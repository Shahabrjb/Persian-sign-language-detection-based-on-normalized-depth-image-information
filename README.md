There are many reports of using the Kinect to detect hand and finger gestures after release of device by Microsoft. The depth information is mostly used to separate the hand image in the two-dimension of RGB domain. This paper proposes a method in which the depth information plays a more dominant role. Using a threshold in depth space first the hand template is extracted. Then in 3D domain the perpendicular vector to the hand surface is found. Using the rotation matrix all the rotations along three axes are compensated in a way that the camera z- coordinate lies perpendicular to hand surface. Then the resulted 3d image is translated to a distance of 80 to 100 cm from the Kinect. Wavelet transform with a new descriptor, called Circular Descriptor are used to extract required features. A trained MLP neural network in conjunction with a SVM is used to classify the signs. Empirical results show an average accuracy of 96.7 % with a two seconds delay for online recognition of Persian Sign Language.
